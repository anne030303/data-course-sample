# data-course-sample

## Week3. 實作「Collaborative filtering」推薦算法

### 針對評論資料進行EDA

* 上週針對商品資料進行清理及調整，本週換嘗試針對ratings資料進行分析
* 觀察測試集中有被評論（購買）的產品在整個資料集裡的特性，分別計算商品被評論的總次數、評論頻率、最初及最近一筆評論的時間點
  * 近期有被評論的商品中，最早被評論的商品日期距離2018-09-30有4813天，且購買頻率約為20天
  * 顯示即使評論時間很久之前的商品也可能是頻繁銷售的熱銷商品
  * 購買頻率及購買次數皆可納入考量
* 由於評論分數較主觀，不同使用者評論的4、5分不一定可以被比較，因此將評論分數調整為正面(4, 5)、普通(3)、負面(1, 2)三種評價
* 依據上述說明，評分指標設計為：評論分數（正面、普通、負面）、最近評論距2018-09-30的天數（越近越好）、評論頻率（越高越好）、評論次數（越多越好）
* 將上述四個指標做標準化
* 四項指標總和為商品分數（score）

### 推薦方法

切分資料集：
1. 依照四項指標總和的分數切出高於30%的資料作為訓練集
2. 依照四項指標總和的分數切出高於平均的資料作為訓練集
3. 100%訓練集

熱銷排行榜：
1. 上週採用的“近兩月評論數排名前10的商品”
2. 依照四項指標總和的分數排行前10

三種實作 collaborative filtering 的方法：
1. User-based collaborative filtering
2. Item-based collaborative filtering
3. 套件 surprise 實作 collaborative filtering

### 小結

* 適當的篩選資料集可提升推薦分數及降低運算量
* 在熱銷排行上，近兩月的推薦效果優於依照四項指標得出的分數排行
* 三項實作方法在推薦分數上並無顯著差異

推薦分數：

* 依照四項指標總和的分數切出高於30%的資料作為訓練集

|           | 近兩月評論數排名前10的商品 | 指標總和的分數排行前10 |
|-----------|----------------------------|------------------------|
| UserBased | 0.15084745762711865        | 0.003389830508474576   |
| ItemBased | 0.15084745762711865        | 0.003389830508474576   |
| Surprise  | 0.15254237288135594        | 0.005084745762711864   |

* 依照四項指標總和的分數切出高於平均的資料作為訓練集

|           | 近兩月評論數排名前10的商品 | 指標總和的分數排行前10 |
|-----------|----------------------------|------------------------|
| UserBased | 0.15084745762711865        | 0.003389830508474576   |
| ItemBased | 0.15254237288135594        | 0.005084745762711864   |
| Surprise  | 0.15254237288135594        | 0.005084745762711864   |

* 100%訓練集

|           | 近兩月評論數排名前10的商品 | 指標總和的分數排行前10 |
|-----------|----------------------------|------------------------|
| UserBased | 0.15084745762711865        | 0.003389830508474576   |
| ItemBased | 0.14915254237288136        | 0.005084745762711864   |
| Surprise  | 0.14745762711864407        | 0.005084745762711864   |

## Week2. 實作「Content-based Filtering」的推薦系統

### 清理資料

* 將rank中的排名及類別分開，並只保留有較多資訊可使用的欄位，方便後續作業
* 由於上週分析資料後得知
  * 新用戶比例遠高於曾購買並評論的舊用戶
  * 近期的商品被購買的機會較高
 
因此採用方法如下

### 方法1
* 以商品資訊中的title, brand, description三項作為特徵萃取的目標
* 嘗試給予三項資訊不同的權重，重要性依次為title > brand > description
* 若為舊用戶，先計算購買過的商品各自最相似的10種商品，加總後再排序找到相似分數最高的10樣進行推薦
* 若為新用戶，則提供近兩月評論數排名前10的商品
推薦分數：0.15084745762711865

### 方法2
* 以商品資訊中的title, brand, description三項作為特徵萃取的目標
* 嘗試給予三項資訊不同的權重，重要性依次為title > brand > description
* 若為舊用戶，先計算購買過的商品各自最相似的10種商品，加總後再排序找到相似分數最高的5樣商品，並加入近兩月評論數排名前5名的商品進行推薦
* 若為新用戶，則提供近兩月評論數排名前10的商品
推薦分數：0.15084745762711865

### 小結
* 舊用戶的推薦效果不彰，並沒有成功打到用戶實際購買的商品
* 目前的分數主要來源自rule-based的熱銷商品排行

## Week1. 實作「rule-based」的推薦系統

### 資料集：採用2014 年 Amazon 發布的資料集中「美妝（All Beauty）」類別的商品資料
### 資料內容：
* 評論資料：2000-01-10 - 2018-10-02 (共 371345)
  * 訓練資料：2000-01-10 - 2018-09-01 (共 370752)
  * 測試資料：2018-09-01 - 2018-09-30 (共 590)
* 商品數量：共 32892 個商品

### 採用規則：先抓取指定時間內的評論資料，再透過計算商品評論數
* 第一組：只抓近60天的資料
  * 考量美妝商品推陳出新，消費者可能會選擇近期熱銷商品，因此僅抓取近60天的評論資料
* 第二組：只抓去年同月的資料
  * 有些美妝商品可能是有季節性的，可能適合冬季或夏季使用，因此也嘗試推薦前一年度同時間段購買的商品
* 第三組：近60天的資料與去年同月資料各半
  * 折衷兩種方法做評估

另針對評論分數，分別針對未篩選評論分數及篩選評論分數3以上做評估

### 結果
* 未對評論分數做篩選
  * 第一組：0.15254237288135594
  * 第二組：0.1
  * 第三組：0.09661016949152543
* 篩選評論分數3以上
  * 第一組：0.13728813559322034
  * 第二組：0.09830508474576272
  * 第三組：0.11016949152542373

### 小結
* 前一年度的資料對推薦商品的效益較低
* 評論分數篩選僅在第三組有些微的提升，可能評論分數較主觀，或許對推薦有幫助但幫助不大
